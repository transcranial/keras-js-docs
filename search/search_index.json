{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"**This project is no longer active. Please check out TensorFlow.js .** The Keras.js demos still work but is no longer updated. Run Keras models in the browser, with GPU support using WebGL Introduction Run Keras models in the browser, with GPU support provided by WebGL 2. Models can be run in Node.js as well, but only in CPU mode. Because Keras abstracts away a number of frameworks as backends, the models can be trained in any backend, including TensorFlow, CNTK, etc. Library version compatibility: Keras 2.1.2 Features In GPU mode, computation is performed by WebGL shaders. All layers implement a GPU version of its computation call, so CPU <-> GPU data transfer only occurs at the start and at the end of each predict call. This results in 1-2 orders of magnitude faster performance over CPU mode. There are a myriad of benefits to running neural networks client-side in the browser, including but not limited to: reduced data transfer and latency of server-client communication, the ability to offload computation to end-user clients, privacy and security. There are always tradeoffs to consider, of course. For example, eliminating the need to upload mode input data repeatedly comes at the cost of an initial model file download. Depending on the size of input data and number of uses per model download, this can be a worthwhile tradeoff. Additionally, there are caching and quantization strategies to address this. Limitations WebGL 2 To run GPU mode in the browser, WebGL 2 (which uses the OpenGL ES 3.0 specification) is required. Unfortunately, this is not supported in all browsers, yet. We use extensively features exclusive to WebGL 2 , so this unfortunately is a hard requirement. The capabilities which WebGL 2 affords us greatly outweigh the c`urrent browser restrictions. To date, not all browsers support WebGL 2 , but support by all major browsers should happen at some point in the future. MAX_TEXTURE_SIZE In GPU mode, tensors are encoded as WebGL textures. The size of these tensors are limited by the parameter MAX_TEXTURE_SIZE , which differs by browser/platform/hardware. See here for typical expected values. For operations involving tensors where this value is exceeded along any dimension, we break up the tensor into an array of texture fragments, and perform computation on these fragments. This process naturally incurs some overhead. WebWorkers Keras.js can be run in a WebWorker separate from the main thread. Because Keras.js performs a lot of synchronous computations, this can prevent the DOM from being blocked. However, one of the biggest limitations of WebWorkers is the lack of <canvas> (and thus WebGL) access, so it can only be run in CPU mode for now. In other words, Keras.js in GPU mode can only be run in the main thread. This will not be the case forever: OffscreenCanvas is in development . Lambda layers Currently, there is no way to port custom Lambda layers, as these will need to be re-implemented in JavaScript. In the future, there will be a means to do so. Implemented Layers Advanced Activations ELU LeakyReLU PReLU ThresholdedReLU Convolutional Conv1D Conv2D Conv2DTranspose Conv3D Cropping1D Cropping2D Cropping3D SeparableConv2D UpSampling1D UpSampling2D UpSampling3D ZeroPadding1D ZeroPadding2D ZeroPadding3D Core Activation Dense Dropout Flatten Permute RepeatVector Reshape SpatialDropout1D SpatialDropout2D SpatialDropout3D embeddings Embedding Merge Add Average Concatenate Dot Maximum Minimum Multiply Subtract Noise GaussianDropout GaussianNoise Normalization BatchNormalization Pooling AveragePooling1D AveragePooling2D AveragePooling3D GlobalAveragePooling1D GlobalAveragePooling2D GlobalAveragePooling3D GlobalMaxPooling1D GlobalMaxPooling2D GlobalMaxPooling3D MaxPooling1D MaxPooling2D MaxPooling3D Recurrent GRU LSTM SimpleRNN Wrappers Bidirectional TimeDistributed License MIT","title":"Home"},{"location":"#introduction","text":"Run Keras models in the browser, with GPU support provided by WebGL 2. Models can be run in Node.js as well, but only in CPU mode. Because Keras abstracts away a number of frameworks as backends, the models can be trained in any backend, including TensorFlow, CNTK, etc. Library version compatibility: Keras 2.1.2","title":"Introduction"},{"location":"#features","text":"In GPU mode, computation is performed by WebGL shaders. All layers implement a GPU version of its computation call, so CPU <-> GPU data transfer only occurs at the start and at the end of each predict call. This results in 1-2 orders of magnitude faster performance over CPU mode. There are a myriad of benefits to running neural networks client-side in the browser, including but not limited to: reduced data transfer and latency of server-client communication, the ability to offload computation to end-user clients, privacy and security. There are always tradeoffs to consider, of course. For example, eliminating the need to upload mode input data repeatedly comes at the cost of an initial model file download. Depending on the size of input data and number of uses per model download, this can be a worthwhile tradeoff. Additionally, there are caching and quantization strategies to address this.","title":"Features"},{"location":"#limitations","text":"WebGL 2 To run GPU mode in the browser, WebGL 2 (which uses the OpenGL ES 3.0 specification) is required. Unfortunately, this is not supported in all browsers, yet. We use extensively features exclusive to WebGL 2 , so this unfortunately is a hard requirement. The capabilities which WebGL 2 affords us greatly outweigh the c`urrent browser restrictions. To date, not all browsers support WebGL 2 , but support by all major browsers should happen at some point in the future. MAX_TEXTURE_SIZE In GPU mode, tensors are encoded as WebGL textures. The size of these tensors are limited by the parameter MAX_TEXTURE_SIZE , which differs by browser/platform/hardware. See here for typical expected values. For operations involving tensors where this value is exceeded along any dimension, we break up the tensor into an array of texture fragments, and perform computation on these fragments. This process naturally incurs some overhead. WebWorkers Keras.js can be run in a WebWorker separate from the main thread. Because Keras.js performs a lot of synchronous computations, this can prevent the DOM from being blocked. However, one of the biggest limitations of WebWorkers is the lack of <canvas> (and thus WebGL) access, so it can only be run in CPU mode for now. In other words, Keras.js in GPU mode can only be run in the main thread. This will not be the case forever: OffscreenCanvas is in development . Lambda layers Currently, there is no way to port custom Lambda layers, as these will need to be re-implemented in JavaScript. In the future, there will be a means to do so.","title":"Limitations"},{"location":"#implemented-layers","text":"Advanced Activations ELU LeakyReLU PReLU ThresholdedReLU Convolutional Conv1D Conv2D Conv2DTranspose Conv3D Cropping1D Cropping2D Cropping3D SeparableConv2D UpSampling1D UpSampling2D UpSampling3D ZeroPadding1D ZeroPadding2D ZeroPadding3D Core Activation Dense Dropout Flatten Permute RepeatVector Reshape SpatialDropout1D SpatialDropout2D SpatialDropout3D embeddings Embedding Merge Add Average Concatenate Dot Maximum Minimum Multiply Subtract Noise GaussianDropout GaussianNoise Normalization BatchNormalization Pooling AveragePooling1D AveragePooling2D AveragePooling3D GlobalAveragePooling1D GlobalAveragePooling2D GlobalAveragePooling3D GlobalMaxPooling1D GlobalMaxPooling2D GlobalMaxPooling3D MaxPooling1D MaxPooling2D MaxPooling3D Recurrent GRU LSTM SimpleRNN Wrappers Bidirectional TimeDistributed","title":"Implemented Layers"},{"location":"#license","text":"MIT","title":"License"},{"location":"caching/","text":"","title":"Caching"},{"location":"conversion/","text":"Format Keras.js uses a custom protocol buffer format binary file that is a serialization of the HDF5-format Keras model and weights file. The python/encoder.py script performs this necessary conversion. The HDF5-format Keras model file must include both the model architecture and the weights. This is the default behavior for Keras model saving: model.save('example.h5') Note that when using the ModelCheckpoint callback, save_weights_only must not be set to True (default is False ). Works for both Keras Model and Sequential classes: model = Sequential() model.add(...) ... ... model = Model(inputs=..., outputs=...) Requirements NumPy h5py protobuf 3.4+ Running the script From the python/ directory: ./encoder.py --help usage: encoder.py [-h] [-n NAME] [-q] hdf5_model_filepath positional arguments: hdf5_model_filepath optional arguments: -h, --help show this help message and exit -n NAME, --name NAME model name (defaults to filename without extension if not provided) -q, --quantize quantize weights to 8-bit unsigned int Example: ./encoder.py -q /path/to/model.h5 Quantization The quantize flag enables weights-wise 8-bit uint quantization from 32-bit float, using a simple linear min/max scale calculated for every layer weights matrix. This will result in a roughly 4x reduction in the model file size. For example, the model file for Inception-V3 is reduced from 92 MB to 23 MB. Client-side, Keras.js then restores uint8-quantized weights back to float32 during model initialization. The tradeoff, of course, is slightly reduced performance, which may or may not be perceptible depending on the model type and end application. For a study on the performance effects of quantization, this is an excellent resource.","title":"Model Conversion"},{"location":"conversion/#format","text":"Keras.js uses a custom protocol buffer format binary file that is a serialization of the HDF5-format Keras model and weights file. The python/encoder.py script performs this necessary conversion. The HDF5-format Keras model file must include both the model architecture and the weights. This is the default behavior for Keras model saving: model.save('example.h5') Note that when using the ModelCheckpoint callback, save_weights_only must not be set to True (default is False ). Works for both Keras Model and Sequential classes: model = Sequential() model.add(...) ... ... model = Model(inputs=..., outputs=...)","title":"Format"},{"location":"conversion/#requirements","text":"NumPy h5py protobuf 3.4+","title":"Requirements"},{"location":"conversion/#running-the-script","text":"From the python/ directory: ./encoder.py --help usage: encoder.py [-h] [-n NAME] [-q] hdf5_model_filepath positional arguments: hdf5_model_filepath optional arguments: -h, --help show this help message and exit -n NAME, --name NAME model name (defaults to filename without extension if not provided) -q, --quantize quantize weights to 8-bit unsigned int Example: ./encoder.py -q /path/to/model.h5","title":"Running the script"},{"location":"conversion/#quantization","text":"The quantize flag enables weights-wise 8-bit uint quantization from 32-bit float, using a simple linear min/max scale calculated for every layer weights matrix. This will result in a roughly 4x reduction in the model file size. For example, the model file for Inception-V3 is reduced from 92 MB to 23 MB. Client-side, Keras.js then restores uint8-quantized weights back to float32 during model initialization. The tradeoff, of course, is slightly reduced performance, which may or may not be perceptible depending on the model type and end application. For a study on the performance effects of quantization, this is an excellent resource.","title":"Quantization"},{"location":"development/","text":"Library Run yarn or npm install to install all dependencies. To run all tests, start npm run server and simply go to http://localhost:3000/test/ . All tests will automatically run. Open up browser devtools for additional test data info. For development of Keras.js, start: npm run watch Editing of any file in src/ will trigger webpack to update dist/keras.min.js . The development server explicitly has caching turned off, so simply refresh to load the updated build. Running npm run build will build both a UMD bundle, located in dist/ , as well as babel-transpiled source, located in lib/ . Tests There are extensive tests for each implemented layer. See notebooks/ for the jupyter notebooks creating the structure and data for these tests. These tests are by no means exhaustive, and many more (especially various graph configurations) will be added. Demos Data files for the demos are located at demos/data/ . These are located in the keras-js-demos-data repo--simply clone and copy the contents to demos/data/ . See notebooks/demos/ for the jupyter notebooks creating the HDF5-format Keras model files, which are then used to generate Keras.js binary files. For development of Keras.js demos, start: npm run demos:watch","title":"Development"},{"location":"diagrams/","text":"","title":"Architecture Diagrams"},{"location":"preprocessing/","text":"","title":"Preprocessing"},{"location":"security/","text":"","title":"Security"},{"location":"usage/","text":"See the Setup section ( Browser , Webpack , or Node.js ) for instructions on importing Keras.js as a library. Create new model On instantiation, data is loaded using XHR (same-domain or CORS required), and layers are initialized as a directed acyclic graph. In the browser, URLs can be relative or absolute: const model = new KerasJS.Model({ filepath: 'path/to/model.bin', gpu: true }) In Node.js, the gpu flag will always be off, as there is no WebGL interface available. filepath can be a file system path or an absolute URL. If filepath is a file system path, the additional filesystem flag must be specified: const model = new KerasJS.Model({ filepath: 'path/to/model.bin', filesystem: true }) Additional configuration options are available (shown below are default values): { filepath: 'path/to/model.bin', headers: {}, filesystem: false, gpu: false, transferLayerOutputs: false, pauseAfterLayerCalls: false, visualizations: [] } headers - Pass in additional headers during file request, authorization credentials or cache control settings, for example. transferLayerOutputs - In GPU mode, this setting will transfer the outputs of each layer from GPU to CPU so that they can be accessed (e.g., for visualization purposes -- see the MNIST CNN or MNIST VAE demos). Otherwise, they will remain as WebGL texture objects. Turning this on will significantly slow down performance. pauseAfterLayerCalls - Turning this on will chunk synchronous calls on Model.predict() to per-layer instead of per-model. This allows DOM updates and other main thread operations to proceed after each layer. Otherwise, Model.predict() will block the event loop during the duration of the call. visualizations - Array of visualizations to activate. See the visualizations section for further details. Predict The class method ready() returns a Promise which resolves when initialization steps are complete. Then, use predict() to run a forward pass with the input data (also returns a Promise). For Keras Model models, the input data object has keys corresponding to the names of the input layers. For Sequential models, the single key should be input . Values are the flattened Float32Array representations of the input data. Input tensor shapes are specified in the model config. Similarly, the output data object has keys corresponding to the names of the output layers for Keras Model models. For Sequential models, the single key will be output . model .ready() .then(() => { // input data object keyed by names of the input layers // or `input` for Sequential models // values are the flattened Float32Array data // (input tensor shapes are specified in the model config) const inputData = { input_1: new Float32Array(data) } // make predictions return model.predict(inputData) }) .then(outputData => { // outputData is an object keyed by names of the output layers // or `output` for Sequential models // e.g., // outputData['fc1000'] }) .catch(err => { // handle error }) Alternatively, we could also use async/await: try { await model.ready() const inputData = { input_1: new Float32Array(data) } const outputData = await model.predict(inputData) } catch (err) { // handle error }","title":"Usage"},{"location":"usage/#create-new-model","text":"On instantiation, data is loaded using XHR (same-domain or CORS required), and layers are initialized as a directed acyclic graph. In the browser, URLs can be relative or absolute: const model = new KerasJS.Model({ filepath: 'path/to/model.bin', gpu: true }) In Node.js, the gpu flag will always be off, as there is no WebGL interface available. filepath can be a file system path or an absolute URL. If filepath is a file system path, the additional filesystem flag must be specified: const model = new KerasJS.Model({ filepath: 'path/to/model.bin', filesystem: true }) Additional configuration options are available (shown below are default values): { filepath: 'path/to/model.bin', headers: {}, filesystem: false, gpu: false, transferLayerOutputs: false, pauseAfterLayerCalls: false, visualizations: [] } headers - Pass in additional headers during file request, authorization credentials or cache control settings, for example. transferLayerOutputs - In GPU mode, this setting will transfer the outputs of each layer from GPU to CPU so that they can be accessed (e.g., for visualization purposes -- see the MNIST CNN or MNIST VAE demos). Otherwise, they will remain as WebGL texture objects. Turning this on will significantly slow down performance. pauseAfterLayerCalls - Turning this on will chunk synchronous calls on Model.predict() to per-layer instead of per-model. This allows DOM updates and other main thread operations to proceed after each layer. Otherwise, Model.predict() will block the event loop during the duration of the call. visualizations - Array of visualizations to activate. See the visualizations section for further details.","title":"Create new model"},{"location":"usage/#predict","text":"The class method ready() returns a Promise which resolves when initialization steps are complete. Then, use predict() to run a forward pass with the input data (also returns a Promise). For Keras Model models, the input data object has keys corresponding to the names of the input layers. For Sequential models, the single key should be input . Values are the flattened Float32Array representations of the input data. Input tensor shapes are specified in the model config. Similarly, the output data object has keys corresponding to the names of the output layers for Keras Model models. For Sequential models, the single key will be output . model .ready() .then(() => { // input data object keyed by names of the input layers // or `input` for Sequential models // values are the flattened Float32Array data // (input tensor shapes are specified in the model config) const inputData = { input_1: new Float32Array(data) } // make predictions return model.predict(inputData) }) .then(outputData => { // outputData is an object keyed by names of the output layers // or `output` for Sequential models // e.g., // outputData['fc1000'] }) .catch(err => { // handle error }) Alternatively, we could also use async/await: try { await model.ready() const inputData = { input_1: new Float32Array(data) } const outputData = await model.predict(inputData) } catch (err) { // handle error }","title":"Predict"},{"location":"visualizations/","text":"Overview Visualizations are additional computational steps performed on each Model.predict() call. To enable visualizations, pass in an array of supported visualization method names as a part of the Model constructor configuration options object (see the usage section ). See the ImageNet demos for usage details. Class Activation Mapping (CAM)","title":"Visualizations"},{"location":"visualizations/#overview","text":"Visualizations are additional computational steps performed on each Model.predict() call. To enable visualizations, pass in an array of supported visualization method names as a part of the Model constructor configuration options object (see the usage section ). See the ImageNet demos for usage details.","title":"Overview"},{"location":"visualizations/#class-activation-mapping-cam","text":"","title":"Class Activation Mapping (CAM)"},{"location":"api/layer/","text":"","title":"Layer"},{"location":"api/model/","text":"","title":"Model"},{"location":"api/tensor/","text":"","title":"Tensor"},{"location":"api/webgl2/","text":"","title":"WebGL2"},{"location":"setup/browser/","text":"To directly use the UMD build of Keras.js, include the library in your index.html or html template file. The unpkg CDN is a good way to go here: <script src=\"https://unpkg.com/keras-js\"></script> This will always point to the latest release on NPM. You can also use a specific version/tag via URLs like https://unpkg.com/keras-js@1.0.2 . KerasJS will now be in the global namespace and can be used directly: const model = new KerasJS.Model({ // ... })","title":"Browser"},{"location":"setup/node/","text":"Installation in Node.js is straightforward. The only limitation at this time is that models will be set to CPU mode, even if gpu: true is set in the options for Model . yarn add keras-js # or npm install keras-js --save import KerasJS from 'keras-js' // or const KerasJS = require('keras-js')","title":"Node.js"},{"location":"setup/webpack/","text":"If you use webpack for building your app, you can easily add and import Keras.js as a dependency: yarn add keras-js # or npm install keras-js --save import KerasJS from 'keras-js' Webpack Config The following must be included in your webpack configuration file: node: { fs: 'empty' } Otherwise when building your app's webpack bundle, you may encounter the following error: ERROR in ./node_modules/keras-js/lib/Model.js Module not found: Error: Can't resolve 'fs' in '/usr/src/app/node_modules/keras-js/lib' UglifyJS If you use UglifyJS when building your bundle, it is important that the option compress be set to false . The default is true , so UglifyJS will drop unreferenced functions and variables (simple direct variable assignments do not count as references). This is important, as a bundle built using the default options will not work! For uglifyjs-webpack-plugin 1.0+ (which uses UglifyJS v3 ): new UglifyJsPlugin({ // ... uglifyOptions: { compress: { unused: false } } }) For uglifyjs-webpack-plugin < 1.0: new UglifyJsPlugin({ // ... compress: { unused: false } })","title":"Webpack"}]}